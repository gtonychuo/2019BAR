---
title: UNIT10B：簡單線性回歸 Simple Linear Regression
author: 中山大學管理學院 卓雍然
date: "`r Sys.time()`"
output: 
  html_document:
    highlight: pygments
    theme: flatly
    css: ../style.css
---

```{r results='hide', message=FALSE, warning=FALSE, echo=F}
# Formating Codes.  Do not change the codes in this chunk.<br>
rm(list=ls(all=T))
knitr::opts_chunk$set(comment = NA)
knitr::opts_knit$set(global.par = TRUE)
par(cex=0.8)
options(scipen=20, digits=5, width=80)
if(!require(pacman)) install.packages("pacman")
```
<hr>

```{r results='hide', message=FALSE, warning=FALSE}
pacman::p_load(dplyr, ggplot2, plotly, ggpubr)
```

批發商資料集
```{r}
W = read.csv('data/wholesales.csv')
W$Channel = factor( paste0("Ch",W$Channel) )
W$Region = factor( paste0("Reg",W$Region) )
W[3:8] = lapply(W[3:8], log, base=10)
```
<br><hr>

### [A] 用R做線性回歸 

+ `lm` : 方法
+ `md` : 模型
+ `Milk` : 目標變數 Response, Dependent Variable (DV)
+ `Grocery` : 預測變數 Predictor, Independent Variable (IV)
+ `W` : 資料

```{r}
md = lm(Milk ~ Grocery, W)
```

```{r}
names(md)
```
<br><hr>

### [B] 理論 vs 實證模型

+ 理論模型：$y_i = \beta_0 + \beta_1 x_i + \epsilon_i, \; \epsilon \in i.i.d. Normal Dist.$
    + $\beta_0$, $beta_1$ - 係數
    + $y_i$ - 目標變數
    + $x_i$ - 預測變數
    + $\epsilon_i$ - 誤差 

+ 估計模型：$\hat{y}_i = b_0 + b_1 x_i$
    + `md$coefficient` : $b_0$, $b_1$ - 係數估計值
    + `md$fitted.value` : $\hat{y}_i$ - 目標變數估計值
    + `md$residuals` : $e_i = y - \hat{y}$ - 殘差 

```{r}
y = W$Milk
x = W$Grocery
b0 = md$coef[1]
b1 = md$coef[2]
yhat = b0 + b1 * x 
er = y - yhat
```

```{r}
range(yhat - md$fitted.values)
```

```{r}
range(er - md$residuals)
```
<br><hr>

### [C] 畫出回歸線

$$ Milk_i = b_0 + b_1 Grocery_i$$

```{r fig.height=3.2, fig.width=3.2}
par(cex=0.8, mar=c(4,4,1,1))
plot(W$Grocery, W$Milk, pch=20, col="#80808080")
abline(b0, b1, col='red')
```

```{r fig.height=4.7, fig.width=4.5}
ggplot(aes(Grocery, Milk), data=W) + 
  geom_point(alpha=0.4, size=0.8) + 
  geom_smooth(method="lm", level=0.95, col="red", lwd=0.2) -> p
ggplotly(p)
```

<br>
<span style="font-size:24px"> `r "\U1F5FF"` : </span>
為什麼大部分的資料點都沒有落在95%信心區間呢？

<span style="font-size:24px"> `r "\U1F4A1"` : </span>
模型估計的是$y$的平均值($\bar{y}|x$)、而不是$y$本身！
<br>

<br><hr>

### [D] Model Summary 功能
```{r}
summary(md)
```

+ $\hat{y}_i = 0.8318 + 0.7352 x_i$
    + $b_0=0.8318$ : $x=0$ 時 $y$ 的估計值
    + $b_1=0.7352$ : $x$ 對 $y$ 的平均邊際效果

+ Coefficients:
    + Estimate: 係數估計值
    + Std. Error: 係數估計值的標準差
    + Pr(>|t|): p值 (變數之間沒有關係的機率？)
    + Signif. codes: 顯著水準

<span style="font-size:24px"> `r "\U1F4A1"` : </span>
$b_1$ 係數代表平均而言， $x$ 每增加一單位時，$y$ 會增加的數量
<br>

<br>

##### § 係數的分布
```{r fig.height=3.2, fig.width=7.2}
curve(dnorm(x, 0.7352, 0.0301), -0.1, 1, n=400, xlab=bquote(italic(b[1])),
      main=bquote("The Distribution of Random Variable: " ~ italic(b[1])))
abline(v=qnorm(c(0.025, 0.975),0.7352, 0.0301), col="red")
```
<br>
<span style="font-size:24px"> `r "\U1F4A1"` : </span>
係數($b_0, b_1$)也都是隨機變數
<br>

<br><hr>

### [E] 變異數分解 Decomposition of Variance

+ SST (Total Sum of Sq.) = $\Sigma_i(y_i - \bar{y}_i)^2$

+ SSE (Error Sum of Sq.) = $\Sigma_i(y_i - \hat{y_i})^2 = \Sigma_i e_i^2$

+ SSR (Regression Sum of Sq.) = SST - SSE

+ $R^2$ (判定係數 Determination Coef.) = SSR/SST，模型所能解釋目標變數的變異的能力

```{r}
SST = sum( (y - mean(y))^2 )            # Total Sum of Sq.
SSE = sum( (y - md$fitted.values)^2 )   # Error Sum of Sq.
SSR = SST - SSE                         # Regression Sum of sql
R2 = SSR/SST    # The Propotion of Variance explained by Regressor   
c(SST=SST, SSE=SSE, SSR=SSR, R2=R2)
```

```{r}
cor(md$fitted.values, md$residuals)
```

<br>
<span style="font-size:24px"> `r "\U1F4A1"` : </span>
因為 Cov($\hat{y}$, $e$) = 0， 所以 Var($y$) = Var($\hat{y}+e$) = Var($\hat{y}$) + Var($e$) 

<br><hr>

### [F] 變異數分析 Analysis of Variance (ANOVA)
當預測變數是類別變數時 ...
```{r}
lm(Grocery ~ Region, W) %>% summary
```
<br>
<span style="font-size:24px"> `r "\U1F4A1"` : </span>
The idea of Dummy Variables

+ $\hat{y}_i = 3.6297 + 0.1499 \times Reg2 + 0.0282 \times Reg3$

+ $\hat{y}_{reg1} = 3.6297$

+ $\hat{y}_{reg2} = 3.6297 + 0.1499$

+ $\hat{y}_{reg3} = 3.6297 + 0.0282$

<br>

##### ANOVA 檢定
```{r}
aov(Grocery ~ Region, data = W) %>% summary
```
$p=0.21 > 0.05$ 不能拒絕各區域(`Region`)雜貨購貨量(`Grocery`)的平均值之間沒有差異的虛無假設

<span style="font-size:24px"> `r "\U1F4A1"` : </span>
其實做Simple Regression和ANOVA檢定之前分別都有一些前提假設和殘差分析需要確認，
詳情請看[教科書](https://cran.r-project.org/web/packages/IPSUR/vignettes/IPSUR.pdf)

##### Kruskal-Wallis 檢定
```{r}
df = ToothGrowth
head(df)
```

[`ggpubr`套件](http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/)
裡面有自動化工具可以做整體和個別檢定並畫出圖形
```{r}
compare <- list( c("0.5", "1"), c("1", "2"), c("0.5", "2") )
ggboxplot(
  df, x = "dose", y = "len",
  color = "dose", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
  add = "jitter", shape = "dose") +
  stat_compare_means(comparisons = compare) + 
  stat_compare_means(label.y = 50)        
```




<br><br><br><hr>



